# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J36ROVgZ6CGDB4LEq9zoMFcBteFkLfYM

CELL 1 – Install Required Libraries (Capstone_Project_FAW_Dataset_v4.1.0)
"""

# ============================================================
# CAPSTONE_PROJECT_FAW_DATASET_v4.1.0
# STEP 1: INSTALL ALL REQUIRED LIBRARIES FOR BINARY CLASSIFICATION PIPELINE
# ============================================================

# Upgrade pip first
!pip install -q --upgrade pip

# Install PyTorch packages
!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install supporting deep learning + image processing modules
!pip install -q timm
!pip install -q albumentations==1.3.0
!pip install -q pandas scikit-learn matplotlib pillow

# Install ONNX + runtime for export and deployment later
!pip install -q onnx onnxruntime torchmetrics

# Check versions to confirm everything is installed correctly
import torch, torchvision, timm, albumentations, pandas, sklearn, onnxruntime
print("torch:", torch.__version__)
print("timm:", timm.__version__)
print("albumentations:", albumentations.__version__)
print("onnxruntime:", onnxruntime.__version__)

"""CELL 2 – Mount Google Drive + Verify Dataset Path + Count Images"""

# =======================
# CELL 2 - MOUNT + SET PATHS
# =======================

from google.colab import drive
drive.mount('/content/drive')

# Base dataset folder
base_path = "/content/drive/MyDrive/Capstone_Project_FAW_Dataset_v4.1"

# Re-declare dataset paths (IMPORTANT) - Corrected casing
pos_path = base_path + "/Positive_Faw_Dataset"
neg_path = base_path + "/Negative_Faw_Dataset"

print("POS Path:", pos_path)
print("NEG Path:", neg_path)

# Check dataset existence
import os

print("Dataset Exists:", os.path.exists(base_path))

# Define valid image extensions (needed by subsequent cells)
valid_extensions = ('.jpg', '.jpeg', '.png', '.webp')
print(f"Counting images with extensions: {', '.join(valid_extensions)}")

# Count images just to verify connectivity
total_images_count = 0
if os.path.exists(base_path):
    for root, _, files in os.walk(base_path):
        for file in files:
            if file.lower().endswith(valid_extensions):
                total_images_count += 1
print("Total Images Found:", total_images_count)

"""CELL 3 – Standardize Filenames + Convert All to .jpg"""

# ===========================
# CELL 3 - STANDARDIZE FILENAMES + CONVERT TO .JPG
# ===========================
import os
from PIL import Image

def standardize_and_convert(folder_path, prefix):
    count = 0
    for root_dir, subdirs, files in os.walk(folder_path):
        for file in files:
            file_path = os.path.join(root_dir, file)
            try:
                img = Image.open(file_path).convert("RGB")

                new_name = f"{prefix}_{count}.jpg"
                new_path = os.path.join(root_dir, new_name)

                img.save(new_path, "JPEG")

                if new_name != file:
                    os.remove(file_path)

                count += 1

            except:
                print("Error with:", file_path)

    print(f"Completed {prefix} | Total Converted: {count}")

# Run for both Positive + Negative dataset folders
standardize_and_convert(pos_path, "FAW_POS")
standardize_and_convert(neg_path, "FAW_NEG")

print("Filename Standardization + JPG Conversion DONE ✅")

"""Cell 4 – Create CSV Metadata"""

# ===========================
# Cell 4 – Create CSV Metadata
# ===========================

import os
import pandas as pd

# function to extract metadata from folder structure
def generate_csv_metadata(base_folder, output_csv):
    data = []

    for root, dirs, files in os.walk(base_folder):
        for file in files:
            if file.lower().endswith(valid_extensions): # Filter by valid extensions
                file_path = os.path.join(root, file)

                # Extract relative folder path
                rel_path = os.path.relpath(root, base_folder)
                parts = rel_path.split(os.sep)

                # Initialize default metadata
                crop_type = ""
                growth_stage = ""
                scenario_type = ""
                class_label = None # Initialize as None, not empty string, to clearly indicate missing if not set

                # Determine dataset type (Positive / Negative) - Make comparison case-insensitive
                # Check for class folder names within the full path (more robust)
                root_lower = root.lower()
                if "positive_faw_dataset" in root_lower:
                    class_label = 1
                elif "negative_faw_dataset" in root_lower:
                    class_label = 0

                # Assign metadata based on folder depth
                if len(parts) == 2:  # Crop Biodiversity Type
                    crop_type = parts[1]
                elif len(parts) == 3:  # Growth Stage Type
                    crop_type = parts[1]
                    growth_stage = parts[2]
                elif len(parts) == 3 or len(parts) == 4:  # Scenario Type
                    scenario_type = parts[-1]

                # Append row
                data.append({
                    "file_path": file_path,
                    "class_label": class_label,
                    "crop_type": crop_type,
                    "growth_stage": growth_stage,
                    "scenario_type": scenario_type
                })

    # Create DataFrame and save CSV
    df = pd.DataFrame(data)
    df.to_csv(output_csv, index=False)
    print(f"CSV Metadata created: {output_csv} | Total images: {len(df)}")

# Specify output CSV path
csv_output_path = base_path + "/faw_metadata.csv"

# Run the function on the main dataset folder
generate_csv_metadata(base_path, csv_output_path)

"""Cell 5 – Train / Test 75% / 25% Split"""

import pandas as pd
from sklearn.model_selection import train_test_split

# Load the CSV metadata created in cell 4
df = pd.read_csv(csv_output_path)

# Check for missing values
print("Missing values per column:\n", df.isna().sum())

# Drop rows with missing class_label (or any critical column)
df = df.dropna(subset=['class_label'])

# Reset index after dropping rows
df = df.reset_index(drop=True)

# Split into Train (75%) and Test (25%) with stratification
train_df, test_df = train_test_split(df, test_size=0.25, stratify=df['class_label'], random_state=42)

# Save split CSVs for reference
train_csv_path = base_path + "/faw_train.csv"
test_csv_path = base_path + "/faw_test.csv"
train_df.to_csv(train_csv_path, index=False)
test_df.to_csv(test_csv_path, index=False)

print(f"Train/Test split completed ✅")
print(f"Train samples: {len(train_df)} | Test samples: {len(test_df)}")

"""Cell 6 – Image Preprocessing, Resize (224x224), Normalization & Augmentation (10x)"""

# ===========================
# CELL 6 - IMAGE PREPROCESSING, RESIZE, NORMALIZATION & AUGMENTATION
# ===========================
import cv2
import numpy as np
import albumentations as A
from tqdm import tqdm
import os

# Define augmentation pipeline (10 variations)
augment_pipeline = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.RandomRotate90(p=0.5),
    A.RandomBrightnessContrast(p=0.5),
    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5),
    A.HueSaturationValue(p=0.5)
])

# Function to preprocess images
def preprocess_images(df, output_folder, augment=True):
    os.makedirs(output_folder, exist_ok=True)
    for idx, row in tqdm(df.iterrows(), total=len(df)):
        img_path = row['file_path']
        class_label = row['class_label']

        # Read and resize
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (224, 224))

        # Normalize pixel values to 0-1
        img = img / 255.0

        # Save original preprocessed image
        save_dir = os.path.join(output_folder, str(class_label)) # Convert class_label to string
        os.makedirs(save_dir, exist_ok=True)
        save_path = os.path.join(save_dir, os.path.basename(img_path))
        cv2.imwrite(save_path, (img * 255).astype(np.uint8))

        # Apply augmentation 10x per image if enabled
        if augment:
            for i in range(10):
                augmented = augment_pipeline(image=(img * 255).astype(np.uint8))['image']
                aug_name = os.path.splitext(os.path.basename(img_path))[0] + f"_aug{i}.jpg"
                cv2.imwrite(os.path.join(save_dir, aug_name), augmented)

# Apply preprocessing & augmentation to train and test sets
preprocessed_train_folder = base_path + "/preprocessed_train"
preprocessed_test_folder = base_path + "/preprocessed_test"

preprocess_images(train_df, preprocessed_train_folder, augment=True)
preprocess_images(test_df, preprocessed_test_folder, augment=True)

print("Image preprocessing, resizing, normalization & augmentation DONE ✅")

"""Cell 7 – Train CNN Binary Classification Model"""

# ===========================
# Cell 7 – Train CNN Binary Classification Model
# ===========================

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms, models
import numpy as np
from PIL import Image # Import Image from PIL

# ----- Custom Dataset -----
class FAWDataset(Dataset):
    def __init__(self, df, transform=None): # Corrected: __init__
        self.df = df
        self.transform = transform

    def __len__(self): # Corrected: __len__
        return len(self.df)

    def __getitem__(self, idx): # Corrected: __getitem__
        img_path = self.df.iloc[idx]['file_path']
        label = int(self.df.iloc[idx]['class_label'])

        image = Image.open(img_path).convert('RGB')
        if self.transform:
            image = self.transform(image)

        return image, label

# ----- Transforms for Training -----
train_transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485,0.456,0.406],
                         std=[0.229,0.224,0.225])
])

# ----- Load Preprocessed Train Dataset -----
train_dataset = FAWDataset(train_df, transform=train_transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# ----- Define CNN Model -----
# Using pretrained ResNet18 for simplicity
model = models.resnet18(pretrained=True)
# Modify final layer for binary classification
model.fc = nn.Linear(model.fc.in_features, 1)
model = model.cuda()  # move to GPU if available

# ----- Loss & Optimizer -----
criterion = nn.BCEWithLogitsLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

# ----- Training Loop -----
num_epochs = 10
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for images, labels in train_loader:
        images = images.cuda()
        labels = labels.float().unsqueeze(1).cuda()  # shape: [batch,1]

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * images.size(0)
        preds = torch.sigmoid(outputs) >= 0.5
        correct += (preds.cpu() == labels.cpu()).sum().item()
        total += labels.size(0)

    epoch_loss = running_loss / total
    epoch_acc = correct / total

    print(f"Epoch [{epoch+1}/{num_epochs}] | Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.4f}")

# ----- Save Trained Model -----
model_path = base_path + "/faw_cnn_model.pth"
torch.save(model.state_dict(), model_path)
print(f"Training completed ✅ | Model saved at {model_path}")

"""Cell 8 – Test CNN Binary Classification Model & Print Metrics"""

# ===========================
# Cell 8 – Test CNN Binary Classification Model & Print Metrics
# ===========================

import torch
from torch.utils.data import DataLoader
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns

# ----- Prepare Test Dataset and DataLoader -----
test_dataset = FAWDataset(test_df, transform=test_transform)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# ----- Set Model to Evaluation Mode -----
model.eval()
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

all_labels = []
all_preds = []

# ----- Run Inference on Test Set -----
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        preds = torch.round(torch.sigmoid(outputs)).squeeze()  # Binary classification
        all_labels.extend(labels.cpu().numpy())
        all_preds.extend(preds.cpu().numpy())

# ----- Compute Metrics -----
accuracy = accuracy_score(all_labels, all_preds)
precision = precision_score(all_labels, all_preds)
recall = recall_score(all_labels, all_preds)
f1 = f1_score(all_labels, all_preds)
cm = confusion_matrix(all_labels, all_preds)

print(f"Test Accuracy: {accuracy:.4f}")
print(f"Test Precision: {precision:.4f}")
print(f"Test Recall: {recall:.4f}")
print(f"Test F1-score: {f1:.4f}")

# ----- Confusion Matrix Visualization -----
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative','Positive'], yticklabels=['Negative','Positive'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix – Test Set')
plt.show()

"""Fine Tuning – Improve Recall and Model Performance

Cell: Fine Tuning – Positive-Class Augmentation + Threshold Adjustment
"""

# ===========================
# CELL – Fine Tuning with Positive-Class Augmentation
# ===========================

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset, ConcatDataset
import albumentations as A
from albumentations.pytorch import ToTensorV2
import numpy as np # Added for np.array(Image.open())
from PIL import Image # Added for Image.open()

# ----- Define augmentation only for positive class -----
pos_transform = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.RandomRotate90(p=0.5),
    A.RandomBrightnessContrast(p=0.5),
    A.Resize(224, 224),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Added Normalize
    ToTensorV2()
])

# ----- Define standard transform for negative class -----
neg_transform = A.Compose([
    A.Resize(224, 224),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Added Normalize
    ToTensorV2()
])

# ----- Custom Dataset for FAW binary classification -----
class FAWDataset(Dataset):
    def __init__(self, df, transform=None, positive_augment=False):
        self.df = df
        self.transform = transform
        self.positive_augment = positive_augment

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        image = np.array(Image.open(row['file_path']).convert("RGB"))
        label = row['class_label']

        # Apply positive-class augmentation multiple times
        if self.positive_augment and label == 1:
            augmented = self.transform(image=image)
        else:
            augmented = self.transform(image=image)

        image = augmented['image']
        return image, torch.tensor(label, dtype=torch.float)

# ----- Create datasets -----
train_dataset = FAWDataset(train_df, transform=pos_transform, positive_augment=True)
test_dataset = FAWDataset(test_df, transform=neg_transform)

# ----- DataLoaders -----
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# ----- Define model, optimizer, criterion -----
# Ensure the model is moved to GPU if available and then configure for fine-tuning
# Assuming 'model' variable (from previous cell) is available and already on GPU.
# If not, you might need to re-instantiate and load weights:
# model = models.resnet18(pretrained=False)
# model.fc = nn.Linear(model.fc.in_features, 1)
# model.load_state_dict(torch.load(model_path))
model.to('cuda') # Ensure it's on GPU

# Calculate class weights for BCEWithLogitsLoss
class_counts = train_df['class_label'].value_counts()
# Ensure 0 and 1 keys exist, providing a default of 0 if not
count_neg = class_counts.get(0, 0)
count_pos = class_counts.get(1, 0)
total_counts = count_neg + count_pos

# Avoid division by zero if a class has no samples
weight_neg = total_counts / count_neg if count_neg > 0 else 1.0
weight_pos = total_counts / count_pos if count_pos > 0 else 1.0

class_weights = torch.tensor([weight_neg, weight_pos]).float().to('cuda')

criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights[1].unsqueeze(0)) # pos_weight for positive class
optimizer = optim.Adam(model.parameters(), lr=1e-4)

# ----- Fine-tuning loop -----
num_epochs = 5
model.train()
for epoch in range(num_epochs):
    running_loss = 0.0
    for images, labels in train_loader:
        images, labels = images.to('cuda'), labels.to('cuda').unsqueeze(1)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}")

# ----- Adjust threshold for predictions -----
threshold = 0.4

# ----- Evaluate on test set -----
model.eval()
all_preds, all_labels = [], []
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to('cuda'), labels.to('cuda').unsqueeze(1)
        outputs = torch.sigmoid(model(images))
        preds = (outputs >= threshold).int()
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# ----- Compute metrics -----
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

accuracy = accuracy_score(all_labels, all_preds)
precision = precision_score(all_labels, all_preds)
recall = recall_score(all_labels, all_preds)
f1 = f1_score(all_labels, all_preds)
cm = confusion_matrix(all_labels, all_preds)

print(f"Fine-tuned Test Accuracy: {accuracy:.4f}")
print(f"Fine-tuned Test Precision: {precision:.4f}")
print(f"Fine-tuned Test Recall: {recall:.4f}")
print(f"Fine-tuned Test F1-score: {f1:.4f}")
print("Confusion Matrix:\n", cm)

"""Cell 9 – Export Fine-tuned Model to ONNX"""

# ===========================
# CELL 9 - EXPORT FINE-TUNED MODEL TO ONNX
# ===========================

import torch

# Define export path
onnx_export_path = base_path + "/faw_cnn_binary_classifier.onnx"

# Switch model to evaluation mode
model.eval()

# Create a dummy input with the same shape as your input images (batch_size=1, channels=3, height=224, width=224)
# Move dummy_input to the same device as the model
dummy_input = torch.randn(1, 3, 224, 224).to(next(model.parameters()).device)

# Export the model
torch.onnx.export(
    model,                     # model being exported
    dummy_input,               # model input (or a tuple for multiple inputs)
    onnx_export_path,          # where to save the ONNX model
    export_params=True,        # store trained parameters
    opset_version=12,          # ONNX opset version
    do_constant_folding=True,  # optimize constants
    input_names=['input'],     # input tensor name
    output_names=['output'],   # output tensor name
    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}  # allow variable batch size
)

print(f"Fine-tuned model successfully exported to ONNX ✅\nPath: {onnx_export_path}")

"""Cell 10 – Deploy ONNX Model for Inference"""

# ===========================
# CELL 10 - DEPLOY ONNX MODEL FOR INFERENCE
# ===========================

import onnxruntime as ort
from PIL import Image
import numpy as np
import os

# Define path to exported ONNX model
onnx_model_path = base_path + "/faw_cnn_binary_classifier.onnx" # Corrected filename

# Initialize ONNX runtime session
ort_session = ort.InferenceSession(onnx_model_path)

# Function to preprocess a single image for ONNX model
def preprocess_image_onnx(image_path, img_size=224):
    img = Image.open(image_path).convert("RGB")
    img = img.resize((img_size, img_size))
    img_array = np.array(img).astype(np.float32) / 255.0  # normalize
    img_array = np.transpose(img_array, (2, 0, 1))  # HWC -> CHW
    img_array = np.expand_dims(img_array, axis=0)  # add batch dimension
    return img_array

# Function to predict a single image
def predict_image_onnx(image_path):
    input_tensor = preprocess_image_onnx(image_path)
    # The ONNX model output might be a single probability for the positive class
    # or logits that need sigmoid. Given the training loss is BCEWithLogitsLoss
    # and the last layer is Linear, it's likely logits.
    outputs = ort_session.run(None, {ort_session.get_inputs()[0].name: input_tensor})
    # Assuming the output is a single logit that needs to be passed through sigmoid
    logit = outputs[0][0][0] # Get the single logit output
    prob = 1 / (1 + np.exp(-logit)) # Apply sigmoid manually for a single logit
    label = "FAW_Positive" if prob >= 0.4 else "FAW_Negative" # Use the adjusted threshold
    return label, prob

# Example inference
# Get a sample image path from the training DataFrame
# Make sure train_df is loaded (it should be from previous cells)
if 'train_df' not in locals():
    train_df = pd.read_csv(base_path + "/faw_train.csv")

# Get the first image path from the training DataFrame for testing
sample_image_path = train_df.iloc[0]['file_path'] # Corrected: use an actual image file path

label, prob = predict_image_onnx(sample_image_path)
print(f"Predicted Label: {label} | Probability: {prob:.4f}")
